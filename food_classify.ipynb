{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd7fe50-7106-41a3-8504-ffad34698d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43387da0-a23d-4d78-8f36-c0f3ac3feaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\indian_foods\n",
      "['adhirasam', 'aloo_gobi', 'aloo_matar', 'aloo_methi', 'aloo_shimla_mirch', 'aloo_tikki', 'anarsa', 'ariselu', 'bandar_laddu', 'basundi', 'bhatura', 'bhindi_masala', 'biryani', 'boondi', 'butter_chicken', 'chak_hao_kheer', 'cham_cham', 'chana_masala', 'chapati', 'chhena_kheeri', 'chicken_razala', 'chicken_tikka', 'chicken_tikka_masala', 'chikki', 'daal_baati_churma', 'daal_puri', 'dal_makhani', 'dal_tadka', 'dharwad_pedha', 'doodhpak', 'double_ka_meetha', 'dum_aloo', 'gajar_ka_halwa', 'gavvalu', 'ghevar', 'gulab_jamun', 'imarti', 'jalebi', 'kachori', 'kadai_paneer', 'kadhi_pakoda', 'kajjikaya', 'kakinada_khaja', 'kalakand', 'karela_bharta', 'kofta', 'kuzhi_paniyaram', 'lassi', 'ledikeni', 'litti_chokha', 'lyangcha', 'maach_jhol', 'makki_di_roti_sarson_da_saag', 'malapua', 'misi_roti', 'misti_doi', 'modak', 'mysore_pak', 'naan', 'navrattan_korma', 'palak_paneer', 'paneer_butter_masala', 'phirni', 'pithe', 'poha', 'poornalu', 'pootharekulu', 'qubani_ka_meetha', 'rabri', 'rasgulla', 'ras_malai', 'sandesh', 'shankarpali', 'sheera', 'sheer_korma', 'shrikhand', 'sohan_halwa', 'sohan_papdi', 'sutar_feni', 'unni_appam']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "globalpath='C:\\\\Users\\\\jerar\\\\OneDrive\\\\Desktop\\\\food_classify\\\\indian_foods'\n",
    "os.chdir(globalpath)\n",
    "print(os.getcwd())\n",
    "labels=os.listdir()#list of all foodnames since food name is the directory name\n",
    "print(labels)\n",
    "class_len=len(labels)\n",
    "print(class_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "907d2d58-91f3-4796-b910-7c6bffcc2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image                 label\n",
      "0  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...               bhatura\n",
      "1  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...             misti_doi\n",
      "2  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...  paneer_butter_masala\n",
      "3  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...             dal_tadka\n",
      "4  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...       kuzhi_paniyaram\n"
     ]
    }
   ],
   "source": [
    "data={\"image\":[],\n",
    "    \"label\":[]\n",
    "}\n",
    "for label in labels:\n",
    "    os.chdir(globalpath)\n",
    "    path=os.getcwd()+\"\\\\\"+label\n",
    "    os.chdir(path)\n",
    "    imagelist=os.listdir()\n",
    "    labellist=[]\n",
    "    for i in range(0,len(imagelist)):\n",
    "        imagelist[i]=path+\"\\\\\"+imagelist[i]\n",
    "        labellist.append(label)\n",
    "    data[\"image\"].extend(imagelist)\n",
    "    data[\"label\"].extend(labellist)\n",
    "\n",
    "\n",
    "'''\n",
    "data[\"label\"]=list(encoded_labels)'''\n",
    "#load data into a DataFrame object:\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffling dataframe\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db52a1c-ee26-4693-849b-081356d4832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image label\n",
      "0  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    10\n",
      "1  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    55\n",
      "2  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    61\n",
      "3  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    27\n",
      "4  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    46\n"
     ]
    }
   ],
   "source": [
    "#encoding labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels= encoder.fit_transform(df.iloc[:,1])\n",
    "df.iloc[:,1]=encoded_labels\n",
    "df['label']=df['label'].astype(str)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88ce5c0-4ad5-43bf-96c0-93528b0acb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating tensors from dictionary using tf.data.Dataset.from_tensor_slices(tensors)\n",
    "### tensors should be 1D arrays\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235c6df5-6d3f-4d3e-a8ac-94b796c9cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(df,test_size = 0.30, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e15f5f23-1472-4480-a033-43ff72ae7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,validation_split = 0.2) # rescale + augmentation\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255) # only rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f104d41-f00a-426b-a2f3-fdb111fdf2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2240 validated image filenames belonging to 80 classes.\n",
      "Found 560 validated image filenames belonging to 80 classes.\n",
      "Found 1200 validated image filenames belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image = train_gen.flow_from_dataframe(dataframe = train_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 32,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = True,\n",
    "                                           seed = 42,\n",
    "                                           subset = 'training')\n",
    "val_image = train_gen.flow_from_dataframe(dataframe = train_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 32,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = True,\n",
    "                                           seed = 42,\n",
    "                                           subset = 'validation')\n",
    "test_image = test_gen.flow_from_dataframe(dataframe = test_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 32,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4014bfb-ce6f-4e9f-85e2-481287e0a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70/70 [==============================] - 27s 376ms/step - loss: 0.0127 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 2/100\n",
      "70/70 [==============================] - 27s 382ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 3/100\n",
      "70/70 [==============================] - 27s 379ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 4/100\n",
      "70/70 [==============================] - 26s 374ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 5/100\n",
      "70/70 [==============================] - 27s 383ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 6/100\n",
      "70/70 [==============================] - 27s 385ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 7/100\n",
      "70/70 [==============================] - 26s 374ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 8/100\n",
      "70/70 [==============================] - 27s 386ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 9/100\n",
      "70/70 [==============================] - 27s 389ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 10/100\n",
      "70/70 [==============================] - 27s 382ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 11/100\n",
      "70/70 [==============================] - 27s 379ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 12/100\n",
      "70/70 [==============================] - 27s 382ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 13/100\n",
      "70/70 [==============================] - 27s 378ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 14/100\n",
      "70/70 [==============================] - 27s 383ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 15/100\n",
      "70/70 [==============================] - 27s 384ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 16/100\n",
      "70/70 [==============================] - 26s 373ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 17/100\n",
      "70/70 [==============================] - 27s 384ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 18/100\n",
      "70/70 [==============================] - 27s 386ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 19/100\n",
      "70/70 [==============================] - 26s 370ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 20/100\n",
      "70/70 [==============================] - 27s 383ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 21/100\n",
      "70/70 [==============================] - 27s 379ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 22/100\n",
      "70/70 [==============================] - 26s 375ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 23/100\n",
      "70/70 [==============================] - 27s 383ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 24/100\n",
      "70/70 [==============================] - 27s 380ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 25/100\n",
      "70/70 [==============================] - 27s 382ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 26/100\n",
      "70/70 [==============================] - 27s 391ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 27/100\n",
      "70/70 [==============================] - 27s 387ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 28/100\n",
      "70/70 [==============================] - 27s 379ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 29/100\n",
      "70/70 [==============================] - 28s 393ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 30/100\n",
      "70/70 [==============================] - 27s 391ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 31/100\n",
      "70/70 [==============================] - 27s 385ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "70/70 [==============================] - 27s 392ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 33/100\n",
      "70/70 [==============================] - 27s 388ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n",
      "Epoch 34/100\n",
      "70/70 [==============================] - 27s 379ms/step - loss: 0.0123 - accuracy: 0.9875 - val_loss: 0.0123 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (120,120,3))\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size =(3,3), activation = 'relu' )(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size =(3,3), activation = 'relu' )(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation = 'linear')(x)\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'mse',\n",
    "             metrics = ['accuracy'])\n",
    "history  = model.fit(train_image,\n",
    "                    validation_data = val_image,\n",
    "                    epochs = 100,\n",
    "                    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor = 'val_loss',\n",
    "                    patience = 5,\n",
    "                    restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a910250-02c8-4eda-ad07-56137fd81550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 0.012\n",
      "Test Accuracy : 98.750%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_image, verbose = 0)\n",
    "print('Test Loss : {:.3f}'.format(result[0]))\n",
    "print('Test Accuracy : {:.3f}%'.format(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362a3a8-60d0-48b8-acd5-d13d71f9c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545bb7a-acd0-4eea-8ae1-ab9a9e3a115e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a6505-fa05-4ccd-a012-d7cfb120cf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foodclassify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
