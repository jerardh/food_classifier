{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd7fe50-7106-41a3-8504-ffad34698d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43387da0-a23d-4d78-8f36-c0f3ac3feaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\indian_foods\\dataset\\Dataset\\train\n",
      "['burger', 'butter_naan', 'chai', 'chapati', 'chole_bhature', 'dal_makhani', 'dhokla', 'fried_rice', 'idli', 'jalebi', 'kaathi_rolls', 'kadai_paneer', 'kulfi', 'masala_dosa', 'momos', 'paani_puri', 'pakode', 'pav_bhaji', 'pizza', 'samosa']\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "globalpath=r'C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\indian_foods\\dataset\\Dataset\\train'\n",
    "os.chdir(globalpath)\n",
    "print(os.getcwd())\n",
    "labels=os.listdir()#list of all foodnames since food name is the directory name\n",
    "print(labels)\n",
    "class_len=len(labels)\n",
    "print(class_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907d2d58-91f3-4796-b910-7c6bffcc2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image          label\n",
      "0  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    masala_dosa\n",
      "1  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    masala_dosa\n",
      "2  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...  chole_bhature\n",
      "3  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...      pav_bhaji\n",
      "4  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...           idli\n"
     ]
    }
   ],
   "source": [
    "data={\"image\":[],\n",
    "    \"label\":[]\n",
    "}\n",
    "for label in labels:\n",
    "    os.chdir(globalpath)\n",
    "    path=os.getcwd()+\"\\\\\"+label\n",
    "    os.chdir(path)\n",
    "    imagelist=os.listdir()\n",
    "    labellist=[]\n",
    "    for i in range(0,len(imagelist)):\n",
    "        imagelist[i]=path+\"\\\\\"+imagelist[i]\n",
    "        labellist.append(label)\n",
    "    data[\"image\"].extend(imagelist)\n",
    "    data[\"label\"].extend(labellist)\n",
    "\n",
    "\n",
    "'''\n",
    "data[\"label\"]=list(encoded_labels)'''\n",
    "#load data into a DataFrame object:\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sample(frac=1).reset_index(drop=True) # shuffling dataframe\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db52a1c-ee26-4693-849b-081356d4832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image label\n",
      "0  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    13\n",
      "1  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    13\n",
      "2  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...     4\n",
      "3  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...    17\n",
      "4  C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\\...     8\n"
     ]
    }
   ],
   "source": [
    "#encoding labels\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels= encoder.fit_transform(df.iloc[:,1])\n",
    "df.iloc[:,1]=encoded_labels\n",
    "df['label']=df['label'].astype(str)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d88ce5c0-4ad5-43bf-96c0-93528b0acb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating tensors from dictionary using tf.data.Dataset.from_tensor_slices(tensors)\n",
    "### tensors should be 1D arrays\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "235c6df5-6d3f-4d3e-a8ac-94b796c9cdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df=train_test_split(df,test_size = 0.10, shuffle = True, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15f5f23-1472-4480-a033-43ff72ae7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,validation_split = 0.2,rotation_range=30.horizontal_flip=True,fill_mode='nearest') # rescale + augmentation\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255) # only rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f104d41-f00a-426b-a2f3-fdb111fdf2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2877 validated image filenames belonging to 20 classes.\n",
      "Found 719 validated image filenames belonging to 20 classes.\n",
      "Found 400 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image = train_gen.flow_from_dataframe(dataframe = train_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 16,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = True,\n",
    "                                           seed = 42,\n",
    "                                           subset = 'training')\n",
    "val_image = train_gen.flow_from_dataframe(dataframe = train_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 16,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = True,\n",
    "                                           seed = 42,\n",
    "                                           subset = 'validation')\n",
    "test_image = test_gen.flow_from_dataframe(dataframe = test_df,\n",
    "                                           x_col = 'image',\n",
    "                                           y_col = 'label',\n",
    "                                           target_size = (224,224),\n",
    "                                           batch_size = 16,\n",
    "                                           color_mode = 'rgb',\n",
    "                                           class_mode = 'categorical',\n",
    "                                           shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4014bfb-ce6f-4e9f-85e2-481287e0a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "180/180 [==============================] - 109s 603ms/step - loss: 2.9577 - accuracy: 0.0730 - val_loss: 2.8636 - val_accuracy: 0.0946\n",
      "Epoch 2/50\n",
      "180/180 [==============================] - 112s 621ms/step - loss: 2.7861 - accuracy: 0.1185 - val_loss: 2.7615 - val_accuracy: 0.1085\n",
      "Epoch 3/50\n",
      "180/180 [==============================] - 104s 576ms/step - loss: 2.7197 - accuracy: 0.1265 - val_loss: 2.7315 - val_accuracy: 0.1446\n",
      "Epoch 4/50\n",
      "180/180 [==============================] - 106s 587ms/step - loss: 2.6848 - accuracy: 0.1453 - val_loss: 2.7045 - val_accuracy: 0.1377\n",
      "Epoch 5/50\n",
      "180/180 [==============================] - 108s 596ms/step - loss: 2.6378 - accuracy: 0.1582 - val_loss: 2.7915 - val_accuracy: 0.1057\n",
      "Epoch 6/50\n",
      "180/180 [==============================] - 109s 609ms/step - loss: 2.5847 - accuracy: 0.1773 - val_loss: 2.5990 - val_accuracy: 0.1766\n",
      "Epoch 7/50\n",
      "180/180 [==============================] - 109s 605ms/step - loss: 2.5353 - accuracy: 0.1835 - val_loss: 2.5812 - val_accuracy: 0.1975\n",
      "Epoch 8/50\n",
      "180/180 [==============================] - 107s 598ms/step - loss: 2.5002 - accuracy: 0.2006 - val_loss: 2.5280 - val_accuracy: 0.1878\n",
      "Epoch 9/50\n",
      "180/180 [==============================] - 108s 603ms/step - loss: 2.4525 - accuracy: 0.2131 - val_loss: 2.4944 - val_accuracy: 0.1739\n",
      "Epoch 10/50\n",
      "180/180 [==============================] - 106s 587ms/step - loss: 2.4248 - accuracy: 0.2197 - val_loss: 2.4969 - val_accuracy: 0.2086\n",
      "Epoch 11/50\n",
      "180/180 [==============================] - 111s 617ms/step - loss: 2.4015 - accuracy: 0.2308 - val_loss: 2.4332 - val_accuracy: 0.2142\n",
      "Epoch 12/50\n",
      "180/180 [==============================] - 106s 591ms/step - loss: 2.3718 - accuracy: 0.2398 - val_loss: 2.4009 - val_accuracy: 0.2295\n",
      "Epoch 13/50\n",
      "180/180 [==============================] - 105s 584ms/step - loss: 2.3353 - accuracy: 0.2447 - val_loss: 2.4182 - val_accuracy: 0.2281\n",
      "Epoch 14/50\n",
      "180/180 [==============================] - 106s 584ms/step - loss: 2.3219 - accuracy: 0.2537 - val_loss: 2.3962 - val_accuracy: 0.2378\n",
      "Epoch 15/50\n",
      "180/180 [==============================] - 105s 586ms/step - loss: 2.3059 - accuracy: 0.2603 - val_loss: 2.3967 - val_accuracy: 0.2309\n",
      "Epoch 16/50\n",
      "180/180 [==============================] - 105s 583ms/step - loss: 2.2693 - accuracy: 0.2722 - val_loss: 2.4014 - val_accuracy: 0.2587\n",
      "Epoch 17/50\n",
      "180/180 [==============================] - 103s 571ms/step - loss: 2.2612 - accuracy: 0.2735 - val_loss: 2.2836 - val_accuracy: 0.2684\n",
      "Epoch 18/50\n",
      "180/180 [==============================] - 102s 562ms/step - loss: 2.2043 - accuracy: 0.2892 - val_loss: 2.2254 - val_accuracy: 0.2782\n",
      "Epoch 19/50\n",
      "180/180 [==============================] - 101s 558ms/step - loss: 2.1672 - accuracy: 0.3045 - val_loss: 2.1869 - val_accuracy: 0.3213\n",
      "Epoch 20/50\n",
      "180/180 [==============================] - 101s 561ms/step - loss: 2.1490 - accuracy: 0.3142 - val_loss: 2.2401 - val_accuracy: 0.2851\n",
      "Epoch 21/50\n",
      "180/180 [==============================] - 102s 568ms/step - loss: 2.1131 - accuracy: 0.3274 - val_loss: 2.1641 - val_accuracy: 0.2949\n",
      "Epoch 22/50\n",
      "180/180 [==============================] - 102s 564ms/step - loss: 2.1028 - accuracy: 0.3278 - val_loss: 2.2079 - val_accuracy: 0.3088\n",
      "Epoch 23/50\n",
      "180/180 [==============================] - 101s 565ms/step - loss: 2.0803 - accuracy: 0.3417 - val_loss: 2.1378 - val_accuracy: 0.3296\n",
      "Epoch 24/50\n",
      "180/180 [==============================] - 102s 562ms/step - loss: 2.0694 - accuracy: 0.3385 - val_loss: 2.1395 - val_accuracy: 0.3213\n",
      "Epoch 25/50\n",
      "180/180 [==============================] - 101s 561ms/step - loss: 2.0517 - accuracy: 0.3417 - val_loss: 2.1613 - val_accuracy: 0.3004\n",
      "Epoch 26/50\n",
      "180/180 [==============================] - 101s 559ms/step - loss: 2.0407 - accuracy: 0.3458 - val_loss: 2.1603 - val_accuracy: 0.3115\n",
      "Epoch 27/50\n",
      "180/180 [==============================] - 102s 565ms/step - loss: 2.0213 - accuracy: 0.3559 - val_loss: 2.0995 - val_accuracy: 0.3004\n",
      "Epoch 28/50\n",
      "180/180 [==============================] - 101s 564ms/step - loss: 2.0131 - accuracy: 0.3566 - val_loss: 2.1453 - val_accuracy: 0.3032\n",
      "Epoch 29/50\n",
      "180/180 [==============================] - 102s 568ms/step - loss: 1.9979 - accuracy: 0.3622 - val_loss: 2.0998 - val_accuracy: 0.3463\n",
      "Epoch 30/50\n",
      "180/180 [==============================] - 102s 566ms/step - loss: 1.9886 - accuracy: 0.3594 - val_loss: 2.0521 - val_accuracy: 0.3519\n",
      "Epoch 31/50\n",
      "180/180 [==============================] - 102s 566ms/step - loss: 1.9667 - accuracy: 0.3712 - val_loss: 2.0886 - val_accuracy: 0.3505\n",
      "Epoch 32/50\n",
      "180/180 [==============================] - 101s 561ms/step - loss: 1.9567 - accuracy: 0.3789 - val_loss: 2.0671 - val_accuracy: 0.3408\n",
      "Epoch 33/50\n",
      "180/180 [==============================] - 101s 561ms/step - loss: 1.9402 - accuracy: 0.3737 - val_loss: 2.0790 - val_accuracy: 0.3547\n",
      "Epoch 34/50\n",
      "180/180 [==============================] - 102s 568ms/step - loss: 1.9324 - accuracy: 0.3782 - val_loss: 2.0398 - val_accuracy: 0.3574\n",
      "Epoch 35/50\n",
      "180/180 [==============================] - 102s 567ms/step - loss: 1.9321 - accuracy: 0.3709 - val_loss: 2.0928 - val_accuracy: 0.3533\n",
      "Epoch 36/50\n",
      "180/180 [==============================] - 102s 569ms/step - loss: 1.9240 - accuracy: 0.3799 - val_loss: 2.0344 - val_accuracy: 0.3477\n",
      "Epoch 37/50\n",
      "180/180 [==============================] - 102s 564ms/step - loss: 1.9045 - accuracy: 0.3876 - val_loss: 2.0245 - val_accuracy: 0.3713\n",
      "Epoch 38/50\n",
      "180/180 [==============================] - 104s 579ms/step - loss: 1.9010 - accuracy: 0.3910 - val_loss: 2.0044 - val_accuracy: 0.3700\n",
      "Epoch 39/50\n",
      "180/180 [==============================] - 102s 568ms/step - loss: 1.8962 - accuracy: 0.3900 - val_loss: 1.9969 - val_accuracy: 0.3866\n",
      "Epoch 40/50\n",
      "180/180 [==============================] - 129s 718ms/step - loss: 1.8818 - accuracy: 0.3990 - val_loss: 1.9691 - val_accuracy: 0.3811\n",
      "Epoch 41/50\n",
      "180/180 [==============================] - 173s 963ms/step - loss: 1.8602 - accuracy: 0.4081 - val_loss: 1.9914 - val_accuracy: 0.3658\n",
      "Epoch 42/50\n",
      "180/180 [==============================] - 175s 977ms/step - loss: 1.8461 - accuracy: 0.4032 - val_loss: 2.0026 - val_accuracy: 0.3769\n",
      "Epoch 43/50\n",
      "180/180 [==============================] - 173s 965ms/step - loss: 1.8383 - accuracy: 0.4029 - val_loss: 1.9638 - val_accuracy: 0.3950\n",
      "Epoch 44/50\n",
      "180/180 [==============================] - 176s 978ms/step - loss: 1.8340 - accuracy: 0.4178 - val_loss: 1.9709 - val_accuracy: 0.3950\n",
      "Epoch 45/50\n",
      "180/180 [==============================] - 174s 969ms/step - loss: 1.8266 - accuracy: 0.4140 - val_loss: 2.0328 - val_accuracy: 0.3686\n",
      "Epoch 46/50\n",
      "180/180 [==============================] - 187s 1s/step - loss: 1.8288 - accuracy: 0.4056 - val_loss: 1.9425 - val_accuracy: 0.3908\n",
      "Epoch 47/50\n",
      "112/180 [=================>............] - ETA: 55s - loss: 1.8233 - accuracy: 0.4237"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape = (120,120,3))\n",
    "x = tf.keras.layers.Conv2D(filters = 16, kernel_size =(3,3), activation = 'relu' )(inputs)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 32, kernel_size =(3,3), activation = 'relu' )(x)\n",
    "x = tf.keras.layers.MaxPool2D()(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu')(x) #hidden layer\n",
    "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
    "outputs = tf.keras.layers.Dense(class_len, activation = 'softmax')(x) #single neuron with linear activation function\n",
    "model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "history  = model.fit(train_image,\n",
    "                    validation_data = val_image,\n",
    "                    epochs = 50,\n",
    "                    callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor = 'val_loss',\n",
    "                    patience = 5,\n",
    "                    restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5a910250-02c8-4eda-ad07-56137fd81550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss : 3.831\n",
      "Test Accuracy : 9.250%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_image, verbose = 0)\n",
    "print('Test Loss : {:.3f}'.format(result[0]))\n",
    "print('Test Accuracy : {:.3f}%'.format(result[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362a3a8-60d0-48b8-acd5-d13d71f9c311",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545bb7a-acd0-4eea-8ae1-ab9a9e3a115e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5c7a6505-fa05-4ccd-a012-d7cfb120cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(r\"C:\\Users\\jerar\\OneDrive\\Desktop\\food_classify\")\n",
    "model.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "138e2ea8-0354-4faa-9133-13baad97671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651ea28-082d-4601-832f-2996c6c622a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:foodclassify]",
   "language": "python",
   "name": "conda-env-foodclassify-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
